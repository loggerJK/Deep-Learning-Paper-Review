# Deep Learning Paper Review

- 주로 CV 분야의 필수/유명한 논문들을 읽습니다

## Transformer
- [X] Attention Is All You Need (NIPS 2017)
- [Original Paper Link](https://arxiv.org/abs/1706.03762) | Notion | Blog 
- [ ] An Image is Worth 16x16 Words: Transformers for Image Recognition At Scale
- [X] End-to-End Object Detection with Transformers (DETR, ECCV 2020)
- [Original Paper Link](https://arxiv.org/abs/2005.12872) | Notion | [Blog](https://loggerjk.github.io/deeplearning/DETR/) 
- [ ] MLP-Mixer: An all-MLP Architecture for Vision
- [X] Swin Transformer: Hierarchical Vision Transformer using Shifted Windows
- [Original Paper Link](https://arxiv.org/abs/2103.14030) | Notion | Blog 

## Object Detection / Segmentation
- [X] Rich feature hierarchies for accurate object detection and semantic segmentation (R-CNN, CVPR 2014)
- [Original Paper Link](https://arxiv.org/abs/1311.2524) | Notion | [Blog](https://loggerjk.github.io/deeplearning/Paper-R-CNN(2013)/) 
- [X] You Only Look Once: Unified, Real-Time Object Detection (YOLO V1, CVPR 2016)
- [Original Paper Link](https://arxiv.org/abs/1506.02640) | Notion | [Blog](https://loggerjk.github.io/deeplearning/Paper-YOLO-You-Look-Only-Once/) 
- [ ] Faster R-CNN 
- [ ] Mask R-CNN
- [ ] Panoptic Feature Pyramid Networks
- [ ] YOLOv4: Optimal Speed and Accuracy of Object Detection
- [ ] PointRend: Image Segmentation as Rendering
- [ ] Cost Aggregation Is All You Need for Few-Shot Segmentation

## Representation Learning
- [ ] Unsupervised Feature Learning via Non-Parametric Instance Discrimination
- [ ] Momentum Contrast for Unsupervised Visual Representation Learning
- [ ] A Single Framework for Contrastive Learning of Visual Representations
- [ ] Bootstrap Your Own Latent A New Approach to Self-Supervised Learning
- [ ] Exploring Simple Siamese Representation Learning

## Image Generation
- [ ] Generative Adversarial Nets
- [ ] A Style-Based Generator Architecture for Generative Adversarial Networks
- [ ] Unpaired Image-to-Image Translation using Cycle-Consistent Adversarial Networks
- [ ] GAN Dissection: Visualizing and Understanding Generative Adversarial Networks
- [ ] Semantic Image Synthesis with Spatially-Adaptive Normalization

## Vision-and-Language
- [ ] Learning Transferable Visual Models From Natural Language Supervision
- [ ] StyleCLIP: Text-Driven Manipulation of StyleGAN Imagery
- [ ] Zero-Shot Text-to-Image Generation
- [ ] An Empirical Study of Training End-to-End Vision-and-Language Transformers
- [ ] GLIDE: Towards Photorealistic Image Generation and Editing with Text-Guided Diffusion Models

## Depth Estimation
- [ ] Digging Into Self-Supervised Monocular Depth Estimation
- [ ] Pyramid Stereo Matching Network
- [ ] Towards Robust Monocular Depth Estimation: Mixing Datasets for Zero-shot Cross-dataset Transfer
- [ ] On the uncertainty of self-supervised monocular depth estimation
- [ ] Adaptive confidence thresholding for monocular depth estimation

## Correspondence
- [ ] CATs: Cost Aggregation Transformers for Visual Correspondence
- [ ] GLU-Net: Global-Local Universal Network for Dense Flow and Correspondences
- [ ] What Matters in Unsupervised Optical Flow
- [ ] RAFT: Recurrent All-Pairs Field Transforms for Optical Flow
- [ ] COTR: Correspondence Transformer for Matching Across Images

## Implicit Field
- [X] NeRF: Representing Scenes as Neural Radiance Fields for View Synthesis
- [Original Paper Link](https://arxiv.org/abs/2003.08934) | Notion | [Blog](https://loggerjk.github.io/deeplearning/%EB%B2%88%EC%97%AD-NeRF-Representing-Scenes-as-Neural-Radiance-Fields-for-View-Synthesis/) 
- [ ] GIRAFFE: Representing Scenes as Compositional Generative Neural Feature Fields
- [ ] Multiview Neural Surface Reconstruction by Disentangling Geometry and Appearance
- [ ] IBRNet: Learning Multi-View Image-Based Rendering
- [ ] DeepSDF: Learning Contiuous Signed Distance Functions for Shape Representation

## MSRA
- [ ] Playable Environments: Video Manipulation in Space and Time

## VITON
- [ ] Cloth Transformer
